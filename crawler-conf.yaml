###############################
#  MySQL Configuration  #
###############################

mysql.url: "jdbc:mysql://localhost:3306/crawl"
mysql.table: "tescobank"
mysql.user: "root"
mysql.password: "bucfjfyu"

###############################
#  CloudSearch Configuration  #
###############################

# max number of docs to keep in buffer
# before sending to CS irrespective of size limits
cloudsearch.batch.maxSize: 50

# max delay before flushing buffer in seconds
cloudsearch.batch.max.time.buffered: 10

# specify the doc endpoint to use unless in batch dump mode
cloudsearch.endpoint: doc-storm-tescobank-pvukzvttjdqjdowrrliattjypq.eu-west-1.cloudsearch.amazonaws.com

cloudsearch.region: "eu-west-1"

# dump JSON files to temp dir for debugging
# cloudsearch.batch.dump: true

#####################
# GENERIC SC CONFIG #
#####################

sitemap.sniffContent: false

fetcher.server.delay: 1.0
fetcher.server.min.delay: 0.0
fetcher.queue.mode: "byHost"
fetcher.threads.per.queue: 1
fetcher.threads.number: 10

partition.url.mode: "byHost"

# lists the metadata to transfer to the outlinks
# used by Fetcher for redirections, sitemapparser, etc...
metadata.transfer:
- isSitemap
- key2
- key3

http.agent.name: "StormCrawler"
http.agent.version: "1.0"
http.agent.description: "a Storm-based crawler"
http.agent.url: "https://github.com/DigitalPebble/storm-crawler"
http.agent.email: "stormcrawler@digitalpebble.com"

http.accept.language: "en-us,en-gb,en;q=0.7,*;q=0.3"
http.accept: "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
http.content.limit: 65536
http.store.responsetime: true
http.timeout: 10000

http.robots.403.allow: true

protocols: "http,https"
http.protocol.implementation: "com.digitalpebble.storm.crawler.protocol.httpclient.HttpProtocol"
https.protocol.implementation: "com.digitalpebble.storm.crawler.protocol.httpclient.HttpProtocol"

parsefilters.config.file: "tesco.parsefilters.json"
urlfilters.config.file: "tesco.urlfilters.json"

# revisit a page daily (value in minutes)
fetchInterval.default: 1440

# revisit a page with a fetch error after 2 hours (value in minutes)
fetchInterval.fetch.error: 120

# revisit a page with an error every month (value in minutes)
fetchInterval.error: 44640

stormcrawler.indexer.class: "com.digitalpebble.storm.crawler.indexing.StdOutIndexer"

# configuration for the classes extending AbstractIndexerBolt
# indexer.md.filter: "someKey=aValue"
indexer.url.fieldname: "url"
indexer.text.fieldname: "content"
indexer.md.mapping:
- parse.title=title
- parse.keywords=keywords
- description=description

topology.workers: 2
topology.message.timeout.secs: 300
topology.max.spout.pending: 10
topology.debug: false


